{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A.","metadata":{}},{"cell_type":"code","source":"# Step 1: Define the Bilingual Dictionary\ndictionary = {\n    'hello': 'bonjour',\n    'world': 'monde',\n    'my': 'mon',\n    'name': 'nom',\n    'is': 'est',\n    'good': 'bon',\n    'morning': 'matin',\n    'i': 'je',\n    'am': 'suis',\n    'a': 'un',\n    'student': 'Ã©tudiant',\n    'teacher': 'professeur'\n}\n\n# Step 2: Define Grammar Rules\ngrammar_rules = {\n    'SVO': ['subject', 'verb', 'object']  # Subject-Verb-Object structure\n}\n\n# Step 3: Translation Function\ndef translate(sentence):\n    # Convert sentence to lowercase and split into words\n    words = sentence.lower().split()\n    \n    # Translate each word using the dictionary\n    translated_words = [dictionary.get(word, word) for word in words]\n    \n    # Join the translated words into a sentence\n    translated_sentence = ' '.join(translated_words)\n    \n    return translated_sentence\n\n# Example usage\nsentence = \"Hello world\"\ntranslated_sentence = translate(sentence)\nprint(\"Translated sentence:\", translated_sentence)\n\n# Sample input/output interaction\nwhile True:\n    user_input = input(\"Enter an English sentence to translate (or type 'exit' to quit): \")\n    if user_input.lower() in ['exit', 'quit']:\n        print(\"Exiting translation system.\")\n        break\n    \n    translated_output = translate(user_input)\n    print(\"Translated sentence:\", translated_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T07:25:56.457634Z","iopub.execute_input":"2024-10-06T07:25:56.458285Z","iopub.status.idle":"2024-10-06T07:26:26.054783Z","shell.execute_reply.started":"2024-10-06T07:25:56.458229Z","shell.execute_reply":"2024-10-06T07:26:26.053587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Translated sentence: bonjour monde\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter an English sentence to translate (or type 'exit' to quit):  hello world\n"},{"name":"stdout","text":"Translated sentence: bonjour monde\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter an English sentence to translate (or type 'exit' to quit):  hi ramya \n"},{"name":"stdout","text":"Translated sentence: hi ramya\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter an English sentence to translate (or type 'exit' to quit):  hello ramya\n"},{"name":"stdout","text":"Translated sentence: bonjour ramya\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter an English sentence to translate (or type 'exit' to quit):  exit\n"},{"name":"stdout","text":"Exiting translation system.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"B.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport tensorflow_datasets as tfds\n\n# Step 1: Load dataset from CSV using Pandas\ndata_path = '/kaggle/input/en-fr-translation-dataset/en-fr.csv'\ndata = pd.read_csv(data_path)\n\n# Check the first few rows and the column names of the dataframe\nprint(data.head())\nprint(\"Columns in the DataFrame:\", data.columns.tolist())  # Print the actual column names\n\n# Ensure the dataframe contains the required columns\nexpected_columns = ['en', 'fr']\nassert all(col in data.columns for col in expected_columns), f\"CSV must contain {expected_columns} columns\"\n\n# Step 2: Convert the DataFrame to a TensorFlow Dataset\n# Create a TensorFlow dataset from the DataFrame\ntrain_dataset = tf.data.Dataset.from_tensor_slices((data['en'].values, data['fr'].values))\n\n# Print the first example to verify conversion\nfor english, french in train_dataset.take(1):\n    print(f'English: {english.numpy().decode(\"utf-8\")}, French: {french.numpy().decode(\"utf-8\")}')\n\n# Optional: Define constants for batch size and max length\nBATCH_SIZE = 64\nMAX_LENGTH = 40\n\n# Optional: Tokenization process\n# Tokenizer setup for input (English) and output (French)\ntokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n    (en.numpy() for en, fr in train_dataset), target_vocab_size=2**13)\ntokenizer_fr = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n    (fr.numpy() for en, fr in train_dataset), target_vocab_size=2**13)\n\n# Encoding function\ndef encode(en_t, fr_t):\n    en_t = [tokenizer_en.vocab_size] + tokenizer_en.encode(en_t.numpy().decode('utf-8')) + [tokenizer_en.vocab_size + 1]\n    fr_t = [tokenizer_fr.vocab_size] + tokenizer_fr.encode(fr_t.numpy().decode('utf-8')) + [tokenizer_fr.vocab_size + 1]\n    return en_t, fr_t\n\ndef tf_encode(en_t, fr_t):\n    return tf.py_function(encode, [en_t, fr_t], [tf.int64, tf.int64])\n\n# Prepare the dataset with encoding\ntrain_dataset = train_dataset.map(tf_encode)\n\n# Filter sequences longer than MAX_LENGTH\ndef filter_max_length(en, fr, max_length=MAX_LENGTH):\n    return tf.logical_and(tf.size(en) <= max_length, tf.size(fr) <= max_length)\n\ntrain_dataset = train_dataset.filter(filter_max_length)\n\n# Shuffle and batch the dataset\ntrain_dataset = train_dataset.shuffle(20000).padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\ntrain_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n# Print the first training example after processing\nfor en, fr in train_dataset.take(1):\n    print(f'Encoded English: {en.numpy()}')\n    print(f'Encoded French: {fr.numpy()}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T07:35:23.797228Z","iopub.execute_input":"2024-10-06T07:35:23.797669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}